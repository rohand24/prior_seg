{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import pathlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle as sk_shuffle\n",
    "from skimage.util import random_noise\n",
    "import time\n",
    "import os\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from prior_dataloader import RetraceDataLoader, retrace_parser, retrace_parser_synth\n",
    "from torch.utils.data.sampler import SubsetRandomSampler, SequentialSampler\n",
    "from custom_unets import NestedUNet, U_Net, DeepNestedUNet\n",
    "from sync_batchnorm import SynchronizedBatchNorm2d, DataParallelWithCallback, convert_model\n",
    "# from kornia.losses import FocalLoss\n",
    "from pywick.losses import BCEDiceFocalLoss, BinaryFocalLoss\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import glob2\n",
    "import pdb\n",
    "import ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 2 GPUs!\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# rohan_unet = DeepNestedUNet(1,33)\n",
    "rohan_unet = smp.FPN(encoder_name= \"densenet121\",\n",
    "        encoder_depth= 5,\n",
    "        encoder_weights= None,\n",
    "        decoder_pyramid_channels= 256,\n",
    "        decoder_segmentation_channels= 128,\n",
    "        decoder_merge_policy= \"add\",\n",
    "        decoder_dropout= 0.2,\n",
    "        in_channels= 1,\n",
    "        classes= 33,\n",
    "        activation= None,\n",
    "        upsampling= 4\n",
    "    )\n",
    "\n",
    "\n",
    "if torch.cuda.device_count() > 0:\n",
    "      print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "      # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "      rohan_unet = nn.DataParallel(rohan_unet)\n",
    "rohan_unet.load_state_dict(torch.load('/home/rohan/prior_seg/models/prior_fpn_1/fpn_model_epoch_17.0_f1_0.8538.pth'))\n",
    "rohan_unet = rohan_unet.to(device)\n",
    "rohan_unet = convert_model(rohan_unet)\n",
    "rohan_unet = rohan_unet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummaryX import summary\n",
    "# summary(rohan_unet, input_size=(1,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset length:  60178\n",
      "Loaded dataset length: 60178\n",
      "Dataset length synthetic:  300885\n"
     ]
    }
   ],
   "source": [
    "root_dir = '/home/rohan/Datasets/prior_clean/train/'\n",
    "syn_root_dir = '/home/rohan/Datasets/synthetic_prior_clean/train/'\n",
    "\n",
    "# prior_data = RetraceDataLoader(root_dir, syn_root_dir, length = 100)\n",
    "teeth_dataset = RetraceDataLoader(root_dir=root_dir,\n",
    "                                  root_dir_synth=syn_root_dir,\n",
    "                                  image_size=(256,256),\n",
    "                                  length = 'all',# pass 'all' for all\n",
    "                                  transform=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# teeth_dataset[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size:  1354\n",
      "Validation size:  150\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "validation_split = .1\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "batch_size = 40\n",
    "\n",
    "# Creating data indices for training and validation splits:\n",
    "dataset_size = len(teeth_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "def worker_init_fn(worker_id):                                                          \n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    teeth_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4,\n",
    "    shuffle=False,\n",
    "    sampler=train_sampler,\n",
    "    worker_init_fn=worker_init_fn,\n",
    "    pin_memory = True,\n",
    "    drop_last =True\n",
    ")\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "    teeth_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4,\n",
    "    shuffle=False,\n",
    "    sampler=valid_sampler,\n",
    "    worker_init_fn=worker_init_fn,\n",
    "    pin_memory = True,\n",
    "    drop_last =True\n",
    ")\n",
    "print ('Train size: ', len(trainloader))\n",
    "print ('Validation size: ', len(valloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import copy\n",
    "import pdb\n",
    "import pandas as pd\n",
    "\n",
    "dataloaders = {'train': trainloader,'val':valloader}\n",
    "dataset_sizes = {'train':len(trainloader), 'val':len(valloader)}\n",
    "\n",
    "\n",
    "SMOOTH = 1e-6\n",
    "\n",
    "\n",
    "def dice_loss(input, target):\n",
    "    smooth = SMOOTH\n",
    "    \n",
    "    iflat = input.view(-1)\n",
    "    tflat = target.view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    \n",
    "    return 1 - ((2. * intersection + smooth) /\n",
    "              (iflat.sum() + tflat.sum() + smooth))\n",
    "\n",
    "def dice_score(input, target):\n",
    "    smooth = SMOOTH\n",
    "#     print(input.shape)\n",
    "#     ipdb.set_trace()\n",
    "    iflat = input.view(-1)\n",
    "    tflat = target.view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "    \n",
    "    return ((2. * intersection + smooth) /\n",
    "              (iflat.sum() + tflat.sum() + smooth))\n",
    "\n",
    "def dice_per_channel(inputs, target):\n",
    "    \n",
    "    dice_ch = 0.0\n",
    "    for i in range(0, inputs.shape[1]):\n",
    "        inp = inputs[:,i,:,:]\n",
    "        inp = inp.contiguous()\n",
    "        targs = target[:,i,:,:]\n",
    "        targs = targs.contiguous()\n",
    "        dice_chl = dice_score(inp,targs)\n",
    "        dice_ch +=dice_chl\n",
    "    \n",
    "    return dice_ch / (inputs.shape[1])\n",
    "\n",
    "def dice_per_image(inputs, target):\n",
    "    \n",
    "    dice_img = 0.0\n",
    "    for i in range(0, inputs.shape[0]):\n",
    "        inp = inputs[i,:,:,:]\n",
    "        inp = inp.contiguous()\n",
    "        targs = target[i,:,:,:]\n",
    "        targs = targs.contiguous()\n",
    "        dice_im = dice_score(inp,targs)\n",
    "        dice_img +=dice_im\n",
    "    \n",
    "    return dice_img / (inputs.shape[0])\n",
    "\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, writer, num_epochs=15):\n",
    "    start = time.time()\n",
    "    save_dict={}\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 10.0\n",
    "    best_iou = 0.0\n",
    "    best_f1 = 0.0\n",
    "    best_f1_ch = 0.0\n",
    "    best_f1_img = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        ep_start = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        lrate = scheduler.get_lr()[0]\n",
    "        writer.add_scalar('Learning Rate', lrate, epoch)\n",
    "        print('LR {:.5f}'.format(lrate))\n",
    "        \n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "            running_loss = 0.0\n",
    "            running_ious = 0.0\n",
    "            running_f1 = 0.0\n",
    "            running_f1_ch = 0.0\n",
    "            running_f1_img = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "#                 ipdb.set_trace()\n",
    "                inputs = data['image'][:,:,:,:]\n",
    "                labels = data['masks'][:,:,:,:]\n",
    "#               labels = labels.unsqueeze(0)\n",
    "#                 labels = labels.float()\n",
    "                \n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                labels = labels.type(torch.cuda.FloatTensor)\n",
    "                 # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "#               torch.autograd.set_detect_anomaly(True)\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    \n",
    "                    outputs = model(inputs)\n",
    "                    fl = criterion(outputs, labels)\n",
    "                    preds = torch.sigmoid(outputs)\n",
    "#                     ipdb.set_trace()\n",
    "                    \n",
    "                    diceloss = dice_loss(preds,labels)\n",
    "                    loss = fl * 0.8 + diceloss * (1 - 0.8)\n",
    "                    \n",
    "                    bin_preds = preds.clone().detach()\n",
    "                    bin_preds[bin_preds<=0.5]= 0.0\n",
    "                    bin_preds[bin_preds>0.5]= 1.0\n",
    "                    \n",
    "                    f1 = dice_score(bin_preds, labels)\n",
    "                    f1_ch = dice_per_channel(bin_preds,labels)\n",
    "                    f1_img = dice_per_image(bin_preds,labels)\n",
    "                    \n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                    # statistics\n",
    "                    running_loss += loss.data.cpu().numpy() # * inputs.size(0)\n",
    "#                     running_ious += iou.data.cpu().numpy() # * inputs.size(0)\n",
    "                    running_f1 += f1\n",
    "                    running_f1_ch += f1_ch\n",
    "                    running_f1_img += f1_img\n",
    "                    \n",
    "            torch.cuda.empty_cache()\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_f1 = running_f1 / dataset_sizes[phase]\n",
    "            epoch_f1_ch = running_f1_ch / dataset_sizes[phase]\n",
    "            epoch_f1_img = running_f1_img / dataset_sizes[phase]\n",
    "\n",
    "            if phase == 'train':\n",
    "                writer.add_scalar('Loss/train', epoch_loss, epoch)\n",
    "                writer.add_scalar('Hard_Dice/train', epoch_f1, epoch)\n",
    "                writer.add_scalar('Hard_Dice_per_channel/train', epoch_f1_ch, epoch)\n",
    "                writer.add_scalar('Hard_Dice_per_image/train', epoch_f1_img, epoch)\n",
    "            else:\n",
    "                writer.add_scalar('Loss/val', epoch_loss, epoch)\n",
    "                writer.add_scalar('Hard_Dice/val', epoch_f1, epoch)\n",
    "                writer.add_scalar('Hard_Dice_per_channel/val', epoch_f1_ch, epoch)\n",
    "                writer.add_scalar('Hard_Dice_per_image/val', epoch_f1_img, epoch)\n",
    "\n",
    "            print('{} Loss: {:.4f} F1: {:.4f} F1/ch: {:.4f} F1/img: {:.4f}'.format(phase, epoch_loss, epoch_f1, epoch_f1_ch, epoch_f1_img))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_f1 > best_f1:\n",
    "                best_loss = epoch_loss\n",
    "                best_f1 = epoch_f1\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                torch.save(best_model_wts, '/home/rohan/prior_seg/models/prior_fpn_2/fpn_model_epoch_{:.1f}_f1_{:.4f}.pth'.format(epoch, best_f1))\n",
    "            writer.add_scalar('Hard_Dice/best_val', best_f1, epoch)\n",
    "            \n",
    "\n",
    "        print('Epoch completed in {:.4f} seconds'.format(time.time()-ep_start))\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "\n",
    "    time_elapsed = time.time() - start\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best Val F1: {:4f}'.format(best_f1))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Focal Loss alpha = 0.25 gamma = 2.0\n",
      "Epoch 0/69\n",
      "----------\n",
      "LR 0.00040\n",
      "train Loss: 0.0330 F1: 0.8443 F1/ch: 0.7429 F1/img: 0.7470\n",
      "val Loss: 0.0306 F1: 0.8550 F1/ch: 0.7490 F1/img: 0.7560\n",
      "Epoch completed in 906.9858 seconds\n",
      "Epoch 1/69\n",
      "----------\n",
      "LR 0.00040\n",
      "train Loss: 0.0319 F1: 0.8491 F1/ch: 0.7467 F1/img: 0.7544\n",
      "val Loss: 0.0310 F1: 0.8534 F1/ch: 0.7506 F1/img: 0.7515\n",
      "Epoch completed in 910.2401 seconds\n",
      "Epoch 2/69\n",
      "----------\n",
      "LR 0.00040\n",
      "train Loss: 0.0309 F1: 0.8542 F1/ch: 0.7492 F1/img: 0.7596\n",
      "val Loss: 0.0347 F1: 0.8353 F1/ch: 0.7451 F1/img: 0.7489\n",
      "Epoch completed in 912.2636 seconds\n",
      "Epoch 3/69\n",
      "----------\n",
      "LR 0.00040\n",
      "train Loss: 0.0307 F1: 0.8550 F1/ch: 0.7498 F1/img: 0.7600\n",
      "val Loss: 0.0327 F1: 0.8449 F1/ch: 0.7403 F1/img: 0.7608\n",
      "Epoch completed in 909.1654 seconds\n",
      "Epoch 4/69\n",
      "----------\n",
      "LR 0.00040\n",
      "train Loss: 0.0304 F1: 0.8565 F1/ch: 0.7511 F1/img: 0.7615\n",
      "val Loss: 0.0295 F1: 0.8605 F1/ch: 0.7515 F1/img: 0.7681\n",
      "Epoch completed in 910.1948 seconds\n",
      "Epoch 5/69\n",
      "----------\n",
      "LR 0.00036\n",
      "train Loss: 0.0295 F1: 0.8606 F1/ch: 0.7534 F1/img: 0.7644\n",
      "val Loss: 0.0319 F1: 0.8489 F1/ch: 0.7469 F1/img: 0.7178\n",
      "Epoch completed in 913.7919 seconds\n",
      "Epoch 6/69\n",
      "----------\n",
      "LR 0.00038\n",
      "train Loss: 0.0292 F1: 0.8620 F1/ch: 0.7546 F1/img: 0.7688\n",
      "val Loss: 0.0281 F1: 0.8667 F1/ch: 0.7667 F1/img: 0.7779\n",
      "Epoch completed in 909.1597 seconds\n",
      "Epoch 7/69\n",
      "----------\n",
      "LR 0.00038\n",
      "train Loss: 0.0282 F1: 0.8669 F1/ch: 0.7568 F1/img: 0.7716\n",
      "val Loss: 0.0294 F1: 0.8605 F1/ch: 0.7605 F1/img: 0.7673\n",
      "Epoch completed in 911.6969 seconds\n",
      "Epoch 8/69\n",
      "----------\n",
      "LR 0.00038\n",
      "train Loss: 0.0286 F1: 0.8651 F1/ch: 0.7549 F1/img: 0.7722\n",
      "val Loss: 0.0284 F1: 0.8653 F1/ch: 0.7550 F1/img: 0.7804\n",
      "Epoch completed in 910.8569 seconds\n",
      "Epoch 9/69\n",
      "----------\n",
      "LR 0.00038\n",
      "train Loss: 0.0279 F1: 0.8684 F1/ch: 0.7587 F1/img: 0.7760\n",
      "val Loss: 0.0283 F1: 0.8662 F1/ch: 0.7593 F1/img: 0.7756\n",
      "Epoch completed in 911.7252 seconds\n",
      "Epoch 10/69\n",
      "----------\n",
      "LR 0.00034\n",
      "train Loss: 0.0277 F1: 0.8692 F1/ch: 0.7565 F1/img: 0.7746\n",
      "val Loss: 0.0273 F1: 0.8709 F1/ch: 0.7632 F1/img: 0.7710\n",
      "Epoch completed in 910.4336 seconds\n",
      "Epoch 11/69\n",
      "----------\n",
      "LR 0.00036\n",
      "train Loss: 0.0280 F1: 0.8676 F1/ch: 0.7548 F1/img: 0.7755\n",
      "val Loss: 0.0271 F1: 0.8715 F1/ch: 0.7678 F1/img: 0.7829\n",
      "Epoch completed in 910.9655 seconds\n",
      "Epoch 12/69\n",
      "----------\n",
      "LR 0.00036\n",
      "train Loss: 0.0272 F1: 0.8717 F1/ch: 0.7599 F1/img: 0.7782\n",
      "val Loss: 0.0280 F1: 0.8678 F1/ch: 0.7579 F1/img: 0.7725\n",
      "Epoch completed in 910.6956 seconds\n",
      "Epoch 13/69\n",
      "----------\n",
      "LR 0.00036\n",
      "train Loss: 0.0269 F1: 0.8732 F1/ch: 0.7604 F1/img: 0.7782\n",
      "val Loss: 0.0282 F1: 0.8667 F1/ch: 0.7585 F1/img: 0.7793\n",
      "Epoch completed in 911.2837 seconds\n",
      "Epoch 14/69\n",
      "----------\n",
      "LR 0.00036\n",
      "train Loss: 0.0264 F1: 0.8752 F1/ch: 0.7615 F1/img: 0.7817\n",
      "val Loss: 0.0272 F1: 0.8709 F1/ch: 0.7696 F1/img: 0.7835\n",
      "Epoch completed in 913.9414 seconds\n",
      "Epoch 15/69\n",
      "----------\n",
      "LR 0.00033\n",
      "train Loss: 0.0260 F1: 0.8772 F1/ch: 0.7636 F1/img: 0.7840\n",
      "val Loss: 0.0283 F1: 0.8659 F1/ch: 0.7637 F1/img: 0.7757\n",
      "Epoch completed in 910.5322 seconds\n",
      "Epoch 16/69\n",
      "----------\n",
      "LR 0.00034\n",
      "train Loss: 0.0258 F1: 0.8783 F1/ch: 0.7649 F1/img: 0.7829\n",
      "val Loss: 0.0299 F1: 0.8580 F1/ch: 0.7622 F1/img: 0.7641\n",
      "Epoch completed in 912.5186 seconds\n",
      "Epoch 17/69\n",
      "----------\n",
      "LR 0.00034\n",
      "train Loss: 0.0258 F1: 0.8781 F1/ch: 0.7645 F1/img: 0.7842\n",
      "val Loss: 0.0260 F1: 0.8772 F1/ch: 0.7694 F1/img: 0.7882\n",
      "Epoch completed in 911.9727 seconds\n",
      "Epoch 18/69\n",
      "----------\n",
      "LR 0.00034\n",
      "train Loss: 0.0253 F1: 0.8804 F1/ch: 0.7658 F1/img: 0.7880\n",
      "val Loss: 0.0270 F1: 0.8721 F1/ch: 0.7699 F1/img: 0.7837\n",
      "Epoch completed in 908.5788 seconds\n",
      "Epoch 19/69\n",
      "----------\n",
      "LR 0.00034\n",
      "train Loss: 0.0255 F1: 0.8797 F1/ch: 0.7653 F1/img: 0.7878\n",
      "val Loss: 0.0267 F1: 0.8735 F1/ch: 0.7716 F1/img: 0.7897\n",
      "Epoch completed in 911.3483 seconds\n",
      "Epoch 20/69\n",
      "----------\n",
      "LR 0.00031\n",
      "train Loss: 0.0249 F1: 0.8825 F1/ch: 0.7687 F1/img: 0.7881\n",
      "val Loss: 0.0283 F1: 0.8661 F1/ch: 0.7575 F1/img: 0.7779\n",
      "Epoch completed in 911.2467 seconds\n",
      "Epoch 21/69\n",
      "----------\n",
      "LR 0.00033\n",
      "train Loss: 0.0247 F1: 0.8836 F1/ch: 0.7692 F1/img: 0.7898\n",
      "val Loss: 0.0260 F1: 0.8768 F1/ch: 0.7703 F1/img: 0.7893\n",
      "Epoch completed in 908.4301 seconds\n",
      "Epoch 22/69\n",
      "----------\n",
      "LR 0.00033\n",
      "train Loss: 0.0244 F1: 0.8847 F1/ch: 0.7690 F1/img: 0.7908\n",
      "val Loss: 0.0266 F1: 0.8740 F1/ch: 0.7719 F1/img: 0.7855\n",
      "Epoch completed in 907.5293 seconds\n",
      "Epoch 23/69\n",
      "----------\n",
      "LR 0.00033\n",
      "train Loss: 0.0242 F1: 0.8858 F1/ch: 0.7699 F1/img: 0.7926\n",
      "val Loss: 0.0276 F1: 0.8695 F1/ch: 0.7694 F1/img: 0.7809\n",
      "Epoch completed in 909.4686 seconds\n",
      "Epoch 24/69\n",
      "----------\n",
      "LR 0.00033\n",
      "train Loss: 0.0240 F1: 0.8869 F1/ch: 0.7724 F1/img: 0.7943\n",
      "val Loss: 0.0253 F1: 0.8800 F1/ch: 0.7738 F1/img: 0.7868\n",
      "Epoch completed in 916.2856 seconds\n",
      "Epoch 25/69\n",
      "----------\n",
      "LR 0.00029\n",
      "train Loss: 0.0237 F1: 0.8883 F1/ch: 0.7703 F1/img: 0.7957\n",
      "val Loss: 0.0258 F1: 0.8778 F1/ch: 0.7756 F1/img: 0.7950\n",
      "Epoch completed in 914.8790 seconds\n",
      "Epoch 26/69\n",
      "----------\n",
      "LR 0.00031\n",
      "train Loss: 0.0234 F1: 0.8898 F1/ch: 0.7746 F1/img: 0.7980\n",
      "val Loss: 0.0257 F1: 0.8785 F1/ch: 0.7784 F1/img: 0.7934\n",
      "Epoch completed in 916.4686 seconds\n",
      "Epoch 27/69\n",
      "----------\n",
      "LR 0.00031\n",
      "train Loss: 0.0232 F1: 0.8906 F1/ch: 0.7703 F1/img: 0.7983\n",
      "val Loss: 0.0290 F1: 0.8626 F1/ch: 0.7527 F1/img: 0.7734\n",
      "Epoch completed in 910.0993 seconds\n",
      "Epoch 28/69\n",
      "----------\n",
      "LR 0.00031\n",
      "train Loss: 0.0234 F1: 0.8896 F1/ch: 0.7710 F1/img: 0.7969\n",
      "val Loss: 0.0258 F1: 0.8774 F1/ch: 0.7741 F1/img: 0.7912\n",
      "Epoch completed in 909.4760 seconds\n",
      "Epoch 29/69\n",
      "----------\n",
      "LR 0.00031\n",
      "train Loss: 0.0229 F1: 0.8919 F1/ch: 0.7744 F1/img: 0.8005\n",
      "val Loss: 0.0254 F1: 0.8796 F1/ch: 0.7729 F1/img: 0.7932\n",
      "Epoch completed in 911.1912 seconds\n",
      "Epoch 30/69\n",
      "----------\n",
      "LR 0.00028\n",
      "train Loss: 0.0228 F1: 0.8923 F1/ch: 0.7730 F1/img: 0.8009\n",
      "val Loss: 0.0254 F1: 0.8793 F1/ch: 0.7713 F1/img: 0.7940\n",
      "Epoch completed in 912.8927 seconds\n",
      "Epoch 31/69\n",
      "----------\n",
      "LR 0.00029\n",
      "train Loss: 0.0225 F1: 0.8937 F1/ch: 0.7760 F1/img: 0.8015\n",
      "val Loss: 0.0256 F1: 0.8785 F1/ch: 0.7776 F1/img: 0.7925\n",
      "Epoch completed in 910.3674 seconds\n",
      "Epoch 32/69\n",
      "----------\n",
      "LR 0.00029\n",
      "train Loss: 0.0220 F1: 0.8965 F1/ch: 0.7764 F1/img: 0.8026\n",
      "val Loss: 0.0255 F1: 0.8792 F1/ch: 0.7660 F1/img: 0.7899\n",
      "Epoch completed in 913.2241 seconds\n",
      "Epoch 33/69\n",
      "----------\n",
      "LR 0.00029\n",
      "train Loss: 0.0220 F1: 0.8962 F1/ch: 0.7775 F1/img: 0.8040\n",
      "val Loss: 0.0263 F1: 0.8752 F1/ch: 0.7703 F1/img: 0.7772\n",
      "Epoch completed in 910.6083 seconds\n",
      "Epoch 34/69\n",
      "----------\n",
      "LR 0.00029\n",
      "train Loss: 0.0222 F1: 0.8955 F1/ch: 0.7771 F1/img: 0.8020\n",
      "val Loss: 0.0246 F1: 0.8838 F1/ch: 0.7715 F1/img: 0.7927\n",
      "Epoch completed in 912.4306 seconds\n",
      "Epoch 35/69\n",
      "----------\n",
      "LR 0.00027\n",
      "train Loss: 0.0219 F1: 0.8968 F1/ch: 0.7763 F1/img: 0.8045\n",
      "val Loss: 0.0251 F1: 0.8814 F1/ch: 0.7700 F1/img: 0.7914\n",
      "Epoch completed in 912.0801 seconds\n",
      "Epoch 36/69\n",
      "----------\n",
      "LR 0.00028\n",
      "train Loss: 0.0217 F1: 0.8975 F1/ch: 0.7788 F1/img: 0.8067\n",
      "val Loss: 0.0265 F1: 0.8746 F1/ch: 0.7715 F1/img: 0.7966\n",
      "Epoch completed in 909.3446 seconds\n",
      "Epoch 37/69\n",
      "----------\n",
      "LR 0.00028\n",
      "train Loss: 0.0217 F1: 0.8977 F1/ch: 0.7806 F1/img: 0.8047\n",
      "val Loss: 0.0248 F1: 0.8825 F1/ch: 0.7731 F1/img: 0.8001\n",
      "Epoch completed in 912.9021 seconds\n",
      "Epoch 38/69\n",
      "----------\n",
      "LR 0.00028\n",
      "train Loss: 0.0221 F1: 0.8958 F1/ch: 0.7811 F1/img: 0.8052\n",
      "val Loss: 0.0245 F1: 0.8837 F1/ch: 0.7740 F1/img: 0.7981\n",
      "Epoch completed in 911.9468 seconds\n",
      "Epoch 39/69\n",
      "----------\n",
      "LR 0.00028\n",
      "train Loss: 0.0214 F1: 0.8990 F1/ch: 0.7813 F1/img: 0.8085\n",
      "val Loss: 0.0251 F1: 0.8813 F1/ch: 0.7740 F1/img: 0.7963\n",
      "Epoch completed in 909.6800 seconds\n",
      "Epoch 40/69\n",
      "----------\n",
      "LR 0.00025\n",
      "train Loss: 0.0216 F1: 0.8982 F1/ch: 0.7806 F1/img: 0.8066\n",
      "val Loss: 0.0253 F1: 0.8800 F1/ch: 0.7790 F1/img: 0.7938\n",
      "Epoch completed in 910.7437 seconds\n",
      "Epoch 41/69\n",
      "----------\n",
      "LR 0.00027\n",
      "train Loss: 0.0209 F1: 0.9017 F1/ch: 0.7835 F1/img: 0.8101\n",
      "val Loss: 0.0269 F1: 0.8729 F1/ch: 0.7646 F1/img: 0.7889\n",
      "Epoch completed in 911.3529 seconds\n",
      "Epoch 42/69\n",
      "----------\n",
      "LR 0.00027\n",
      "train Loss: 0.0205 F1: 0.9032 F1/ch: 0.7843 F1/img: 0.8115\n",
      "val Loss: 0.0244 F1: 0.8844 F1/ch: 0.7720 F1/img: 0.7955\n",
      "Epoch completed in 911.1266 seconds\n",
      "Epoch 43/69\n",
      "----------\n",
      "LR 0.00027\n",
      "train Loss: 0.0207 F1: 0.9024 F1/ch: 0.7843 F1/img: 0.8122\n",
      "val Loss: 0.0253 F1: 0.8799 F1/ch: 0.7645 F1/img: 0.7998\n",
      "Epoch completed in 910.4784 seconds\n",
      "Epoch 44/69\n",
      "----------\n",
      "LR 0.00027\n",
      "train Loss: 0.0205 F1: 0.9033 F1/ch: 0.7844 F1/img: 0.8146\n",
      "val Loss: 0.0249 F1: 0.8823 F1/ch: 0.7766 F1/img: 0.7991\n",
      "Epoch completed in 911.5357 seconds\n",
      "Epoch 45/69\n",
      "----------\n",
      "LR 0.00024\n",
      "train Loss: 0.0202 F1: 0.9047 F1/ch: 0.7860 F1/img: 0.8132\n",
      "val Loss: 0.0238 F1: 0.8871 F1/ch: 0.7828 F1/img: 0.8038\n",
      "Epoch completed in 913.8442 seconds\n",
      "Epoch 46/69\n",
      "----------\n",
      "LR 0.00025\n",
      "train Loss: 0.0202 F1: 0.9047 F1/ch: 0.7875 F1/img: 0.8149\n",
      "val Loss: 0.0253 F1: 0.8802 F1/ch: 0.7705 F1/img: 0.7883\n",
      "Epoch completed in 910.4164 seconds\n",
      "Epoch 47/69\n",
      "----------\n",
      "LR 0.00025\n",
      "train Loss: 0.0199 F1: 0.9064 F1/ch: 0.7893 F1/img: 0.8170\n",
      "val Loss: 0.0239 F1: 0.8870 F1/ch: 0.7821 F1/img: 0.8036\n",
      "Epoch completed in 911.3018 seconds\n",
      "Epoch 48/69\n",
      "----------\n",
      "LR 0.00025\n",
      "train Loss: 0.0200 F1: 0.9058 F1/ch: 0.7902 F1/img: 0.8154\n",
      "val Loss: 0.0246 F1: 0.8834 F1/ch: 0.7789 F1/img: 0.7950\n",
      "Epoch completed in 910.0897 seconds\n",
      "Epoch 49/69\n",
      "----------\n",
      "LR 0.00025\n",
      "train Loss: 0.0200 F1: 0.9056 F1/ch: 0.7888 F1/img: 0.8164\n",
      "val Loss: 0.0254 F1: 0.8800 F1/ch: 0.7744 F1/img: 0.7904\n",
      "Epoch completed in 914.2824 seconds\n",
      "Epoch 50/69\n",
      "----------\n",
      "LR 0.00023\n",
      "train Loss: 0.0194 F1: 0.9085 F1/ch: 0.7924 F1/img: 0.8165\n",
      "val Loss: 0.0243 F1: 0.8852 F1/ch: 0.7785 F1/img: 0.7967\n",
      "Epoch completed in 911.3823 seconds\n",
      "Epoch 51/69\n",
      "----------\n",
      "LR 0.00024\n",
      "train Loss: 0.0197 F1: 0.9074 F1/ch: 0.7923 F1/img: 0.8172\n",
      "val Loss: 0.0252 F1: 0.8807 F1/ch: 0.7745 F1/img: 0.7962\n",
      "Epoch completed in 913.0809 seconds\n",
      "Epoch 52/69\n",
      "----------\n",
      "LR 0.00024\n",
      "train Loss: 0.0197 F1: 0.9074 F1/ch: 0.7894 F1/img: 0.8184\n",
      "val Loss: 0.0245 F1: 0.8841 F1/ch: 0.7821 F1/img: 0.7986\n",
      "Epoch completed in 908.5525 seconds\n",
      "Epoch 53/69\n",
      "----------\n",
      "LR 0.00024\n",
      "train Loss: 0.0192 F1: 0.9097 F1/ch: 0.7927 F1/img: 0.8182\n",
      "val Loss: 0.0248 F1: 0.8825 F1/ch: 0.7760 F1/img: 0.7980\n",
      "Epoch completed in 914.4459 seconds\n",
      "Epoch 54/69\n",
      "----------\n",
      "LR 0.00024\n",
      "train Loss: 0.0192 F1: 0.9097 F1/ch: 0.7920 F1/img: 0.8204\n",
      "val Loss: 0.0248 F1: 0.8825 F1/ch: 0.7781 F1/img: 0.7972\n",
      "Epoch completed in 915.3878 seconds\n",
      "Epoch 55/69\n",
      "----------\n",
      "LR 0.00022\n",
      "train Loss: 0.0192 F1: 0.9097 F1/ch: 0.7944 F1/img: 0.8203\n",
      "val Loss: 0.0255 F1: 0.8791 F1/ch: 0.7714 F1/img: 0.7969\n",
      "Epoch completed in 913.0940 seconds\n",
      "Epoch 56/69\n",
      "----------\n",
      "LR 0.00023\n",
      "train Loss: 0.0189 F1: 0.9109 F1/ch: 0.7927 F1/img: 0.8208\n",
      "val Loss: 0.0238 F1: 0.8874 F1/ch: 0.7763 F1/img: 0.8052\n",
      "Epoch completed in 911.8117 seconds\n",
      "Epoch 57/69\n",
      "----------\n",
      "LR 0.00023\n",
      "train Loss: 0.0189 F1: 0.9112 F1/ch: 0.7936 F1/img: 0.8198\n",
      "val Loss: 0.0242 F1: 0.8854 F1/ch: 0.7732 F1/img: 0.8004\n",
      "Epoch completed in 909.6733 seconds\n",
      "Epoch 58/69\n",
      "----------\n",
      "LR 0.00023\n",
      "train Loss: 0.0188 F1: 0.9117 F1/ch: 0.7984 F1/img: 0.8209\n",
      "val Loss: 0.0239 F1: 0.8868 F1/ch: 0.7777 F1/img: 0.8026\n",
      "Epoch completed in 912.2905 seconds\n",
      "Epoch 59/69\n",
      "----------\n",
      "LR 0.00023\n",
      "train Loss: 0.0188 F1: 0.9116 F1/ch: 0.7953 F1/img: 0.8225\n",
      "val Loss: 0.0239 F1: 0.8872 F1/ch: 0.7743 F1/img: 0.8042\n",
      "Epoch completed in 911.1943 seconds\n",
      "Epoch 60/69\n",
      "----------\n",
      "LR 0.00021\n",
      "train Loss: 0.0185 F1: 0.9130 F1/ch: 0.7969 F1/img: 0.8247\n",
      "val Loss: 0.0234 F1: 0.8893 F1/ch: 0.7827 F1/img: 0.8070\n",
      "Epoch completed in 913.1795 seconds\n",
      "Epoch 61/69\n",
      "----------\n",
      "LR 0.00022\n",
      "train Loss: 0.0182 F1: 0.9142 F1/ch: 0.8000 F1/img: 0.8259\n",
      "val Loss: 0.0241 F1: 0.8860 F1/ch: 0.7801 F1/img: 0.8044\n",
      "Epoch completed in 909.3529 seconds\n",
      "Epoch 62/69\n",
      "----------\n",
      "LR 0.00022\n",
      "train Loss: 0.0183 F1: 0.9138 F1/ch: 0.7982 F1/img: 0.8251\n",
      "val Loss: 0.0244 F1: 0.8845 F1/ch: 0.7767 F1/img: 0.8021\n",
      "Epoch completed in 912.9575 seconds\n",
      "Epoch 63/69\n",
      "----------\n",
      "LR 0.00022\n",
      "train Loss: 0.0184 F1: 0.9135 F1/ch: 0.7974 F1/img: 0.8251\n",
      "val Loss: 0.0248 F1: 0.8825 F1/ch: 0.7766 F1/img: 0.7949\n",
      "Epoch completed in 910.4408 seconds\n",
      "Epoch 64/69\n",
      "----------\n",
      "LR 0.00022\n",
      "train Loss: 0.0182 F1: 0.9143 F1/ch: 0.8003 F1/img: 0.8257\n",
      "val Loss: 0.0242 F1: 0.8857 F1/ch: 0.7778 F1/img: 0.8057\n",
      "Epoch completed in 913.8843 seconds\n",
      "Epoch 65/69\n",
      "----------\n",
      "LR 0.00020\n",
      "train Loss: 0.0178 F1: 0.9163 F1/ch: 0.8038 F1/img: 0.8277\n",
      "val Loss: 0.0234 F1: 0.8893 F1/ch: 0.7840 F1/img: 0.8037\n",
      "Epoch completed in 913.5329 seconds\n",
      "Epoch 66/69\n",
      "----------\n",
      "LR 0.00021\n",
      "train Loss: 0.0179 F1: 0.9157 F1/ch: 0.8021 F1/img: 0.8270\n",
      "val Loss: 0.0244 F1: 0.8846 F1/ch: 0.7720 F1/img: 0.7980\n",
      "Epoch completed in 913.0904 seconds\n",
      "Epoch 67/69\n",
      "----------\n",
      "LR 0.00021\n",
      "train Loss: 0.0178 F1: 0.9163 F1/ch: 0.8015 F1/img: 0.8272\n",
      "val Loss: 0.0238 F1: 0.8875 F1/ch: 0.7759 F1/img: 0.8013\n",
      "Epoch completed in 911.7655 seconds\n",
      "Epoch 68/69\n",
      "----------\n",
      "LR 0.00021\n",
      "train Loss: 0.0179 F1: 0.9158 F1/ch: 0.8022 F1/img: 0.8271\n",
      "val Loss: 0.0243 F1: 0.8851 F1/ch: 0.7750 F1/img: 0.8026\n",
      "Epoch completed in 912.1550 seconds\n",
      "Epoch 69/69\n",
      "----------\n",
      "LR 0.00021\n",
      "train Loss: 0.0175 F1: 0.9177 F1/ch: 0.8039 F1/img: 0.8302\n",
      "val Loss: 0.0235 F1: 0.8892 F1/ch: 0.7740 F1/img: 0.8002\n",
      "Epoch completed in 911.8213 seconds\n",
      "Training complete in 1063m 27s\n",
      "Best Val F1: 0.889330\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function\n",
    "from torch.autograd import Variable\n",
    "\n",
    "criterion = BinaryFocalLoss(gamma=2.0, alpha=0.25) #torch.nn.BCELoss()\n",
    "print(\"Focal Loss alpha = {:.2f} gamma = {:.1f}\".format(criterion.alpha, criterion.gamma))\n",
    "optimizer = optim.Adam(rohan_unet.parameters(), lr=0.0004)\n",
    "writer = SummaryWriter(log_dir='/home/rohan/prior_seg/logs/prior_fpn_2', filename_suffix = '_fpn')\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.95)\n",
    "# rohan_unet.load_state_dict(torch.load('/home/rohan/caries_seg/models/test_model/128_nestedunet_model_epoch_0.0000_f1_0.1858.pth'))\n",
    "model_trained = train_model(rohan_unet, criterion, optimizer, exp_lr_scheduler, writer = writer, num_epochs=70)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
